{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classifier with Xception using FFHQ dataset for upsampling\n",
    "  \n",
    "  \n",
    "This notebook uses existing Kaggle dataset that consists of a single extract frame from each video for the entire training dataset, in addtion FFHQ dataset is used to balance to uneven distribution between real and fake, consider reduce the number of epoch during training as it takes little over 8 hours with GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YjwlB710mIH_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm,trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AaU3SeKMz_qm"
   },
   "source": [
    "# Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K55cUb_0yTfH"
   },
   "outputs": [],
   "source": [
    "df_train0 = pd.read_json('../input/deepfake/metadata0.json')\n",
    "df_train1 = pd.read_json('../input/deepfake/metadata1.json')\n",
    "df_train2 = pd.read_json('../input/deepfake/metadata2.json')\n",
    "df_train3 = pd.read_json('../input/deepfake/metadata3.json')\n",
    "df_train4 = pd.read_json('../input/deepfake/metadata4.json')\n",
    "df_train5 = pd.read_json('../input/deepfake/metadata5.json')\n",
    "df_train6 = pd.read_json('../input/deepfake/metadata6.json')\n",
    "df_train7 = pd.read_json('../input/deepfake/metadata7.json')\n",
    "df_train8 = pd.read_json('../input/deepfake/metadata8.json')\n",
    "df_train9 = pd.read_json('../input/deepfake/metadata9.json')\n",
    "df_train10 = pd.read_json('../input/deepfake/metadata10.json')\n",
    "df_train11 = pd.read_json('../input/deepfake/metadata11.json')\n",
    "df_train12 = pd.read_json('../input/deepfake/metadata12.json')\n",
    "df_train13 = pd.read_json('../input/deepfake/metadata13.json')\n",
    "df_train14 = pd.read_json('../input/deepfake/metadata14.json')\n",
    "df_train15 = pd.read_json('../input/deepfake/metadata15.json')\n",
    "df_train16 = pd.read_json('../input/deepfake/metadata16.json')\n",
    "df_train17 = pd.read_json('../input/deepfake/metadata17.json')\n",
    "df_train18 = pd.read_json('../input/deepfake/metadata18.json')\n",
    "df_train19 = pd.read_json('../input/deepfake/metadata19.json')\n",
    "df_train20 = pd.read_json('../input/deepfake/metadata20.json')\n",
    "df_train21 = pd.read_json('../input/deepfake/metadata21.json')\n",
    "df_train22 = pd.read_json('../input/deepfake/metadata22.json')\n",
    "df_train23 = pd.read_json('../input/deepfake/metadata23.json')\n",
    "df_train24 = pd.read_json('../input/deepfake/metadata24.json')\n",
    "df_train25 = pd.read_json('../input/deepfake/metadata25.json')\n",
    "df_train26 = pd.read_json('../input/deepfake/metadata26.json')\n",
    "df_train27 = pd.read_json('../input/deepfake/metadata27.json')\n",
    "df_train28 = pd.read_json('../input/deepfake/metadata28.json')\n",
    "df_train29 = pd.read_json('../input/deepfake/metadata29.json')\n",
    "df_train30 = pd.read_json('../input/deepfake/metadata30.json')\n",
    "df_train31 = pd.read_json('../input/deepfake/metadata31.json')\n",
    "df_train32 = pd.read_json('../input/deepfake/metadata32.json')\n",
    "df_train33 = pd.read_json('../input/deepfake/metadata33.json')\n",
    "df_train34 = pd.read_json('../input/deepfake/metadata34.json')\n",
    "df_train35 = pd.read_json('../input/deepfake/metadata35.json')\n",
    "df_train36 = pd.read_json('../input/deepfake/metadata36.json')\n",
    "df_train37 = pd.read_json('../input/deepfake/metadata37.json')\n",
    "df_train38 = pd.read_json('../input/deepfake/metadata38.json')\n",
    "df_train39 = pd.read_json('../input/deepfake/metadata39.json')\n",
    "df_train40 = pd.read_json('../input/deepfake/metadata40.json')\n",
    "df_train41 = pd.read_json('../input/deepfake/metadata41.json')\n",
    "df_train42 = pd.read_json('../input/deepfake/metadata42.json')\n",
    "df_train43 = pd.read_json('../input/deepfake/metadata43.json')\n",
    "df_train44 = pd.read_json('../input/deepfake/metadata44.json')\n",
    "df_train45 = pd.read_json('../input/deepfake/metadata45.json')\n",
    "df_train46 = pd.read_json('../input/deepfake/metadata46.json')\n",
    "df_val1 = pd.read_json('../input/deepfake/metadata47.json')\n",
    "df_val2 = pd.read_json('../input/deepfake/metadata48.json')\n",
    "df_val3 = pd.read_json('../input/deepfake/metadata49.json')\n",
    "df_trains = [df_train0 ,df_train1, df_train2, df_train3, df_train4,\n",
    "             df_train5, df_train6, df_train7, df_train8, df_train9,df_train10,\n",
    "            df_train11, df_train12, df_train13, df_train14, df_train15,df_train16, \n",
    "            df_train17, df_train18, df_train19, df_train20, df_train21, df_train22, \n",
    "            df_train23, df_train24, df_train25, df_train26, df_train27, df_train28, \n",
    "            df_train29, df_train30, df_train31, df_train32, df_train33, df_train34,\n",
    "            df_train34, df_train35, df_train36, df_train37, df_train38, df_train39,\n",
    "            df_train40, df_train41, df_train42, df_train43, df_train44, df_train45,\n",
    "            df_train46]\n",
    "df_vals=[df_val1, df_val2, df_val3]\n",
    "nums = list(range(len(df_trains)+1))\n",
    "LABELS = ['REAL','FAKE']\n",
    "val_nums=[47, 48, 49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "FSPvZdzbzKd5",
    "outputId": "fe78b0b0-aab7-4dfd-d33c-0af316b60f04"
   },
   "outputs": [],
   "source": [
    "def get_path(num,x):\n",
    "    num=str(num)\n",
    "    if len(num)==2:\n",
    "        path='../input/deepfake/DeepFake'+num+'/DeepFake'+num+'/' + x.replace('.mp4', '') + '.jpg'\n",
    "    else:\n",
    "        path='../input/deepfake/DeepFake0'+num+'/DeepFake0'+num+'/' + x.replace('.mp4', '') + '.jpg'\n",
    "    if not os.path.exists(path):\n",
    "       raise Exception\n",
    "    return path\n",
    "paths=[]\n",
    "y=[]\n",
    "for df_train,num in tqdm(zip(df_trains,nums),total=len(df_trains)):\n",
    "    images = list(df_train.columns.values)\n",
    "    for x in images:\n",
    "        try:\n",
    "            paths.append(get_path(num,x))\n",
    "            y.append(LABELS.index(df_train[x]['label']))\n",
    "        except Exception as err:\n",
    "            #print(err)\n",
    "            pass\n",
    "\n",
    "val_paths=[]\n",
    "val_y=[]\n",
    "for df_val,num in tqdm(zip(df_vals,val_nums),total=len(df_vals)):\n",
    "    images = list(df_val.columns.values)\n",
    "    for x in images:\n",
    "        try:\n",
    "            val_paths.append(get_path(num,x))\n",
    "            val_y.append(LABELS.index(df_val[x]['label']))\n",
    "        except Exception as err:\n",
    "            #print(err)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QXIIa5A-zfa3"
   },
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    return cv2.cvtColor(cv2.imread(path),cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def shuffle(X,y):\n",
    "    new_train=[]\n",
    "    for m,n in zip(X,y):\n",
    "        new_train.append([m,n])\n",
    "    random.shuffle(new_train)\n",
    "    X,y=[],[]\n",
    "    for x in new_train:\n",
    "        X.append(x[0])\n",
    "        y.append(x[1])\n",
    "    return X,y\n",
    "\n",
    "import random\n",
    "def get_random_sampling(paths, y, val_paths, val_y):\n",
    "  real=[]\n",
    "  fake=[]\n",
    "  for m,n in zip(paths,y):\n",
    "      if n==0:\n",
    "          real.append(m)\n",
    "      else:\n",
    "          fake.append(m)\n",
    "  # fake=random.sample(fake,len(real))\n",
    "  paths,y=[],[]\n",
    "  for x in real:\n",
    "      paths.append(x)\n",
    "      y.append(0)\n",
    "  for x in fake:\n",
    "      paths.append(x)\n",
    "      y.append(1)\n",
    "\n",
    "  real=[]\n",
    "  fake=[]\n",
    "  for m,n in zip(val_paths,val_y):\n",
    "      if n==0:\n",
    "          real.append(m)\n",
    "      else:\n",
    "          fake.append(m)\n",
    "  # fake=random.sample(fake,len(real))\n",
    "  val_paths,val_y=[],[]\n",
    "  for x in real:\n",
    "      val_paths.append(x)\n",
    "      val_y.append(0)\n",
    "  for x in fake:\n",
    "      val_paths.append(x)\n",
    "      val_y.append(1)\n",
    "\n",
    "  X=[]\n",
    "  for img in tqdm(paths):\n",
    "      X.append(read_img(img))\n",
    "  val_X=[]\n",
    "  for img in tqdm(val_paths):\n",
    "      val_X.append(read_img(img))\n",
    "\n",
    "  # Balance with ffhq dataset\n",
    "  ffhq = os.listdir('../input/ffhq-face-data-set/thumbnails128x128')\n",
    "  X_ = []\n",
    "  for file in tqdm(ffhq):\n",
    "    im = read_img(f'../input/ffhq-face-data-set/thumbnails128x128/{file}')\n",
    "    im = cv2.resize(im, (150,150))\n",
    "    X_.append(im)\n",
    "  random.shuffle(X_)\n",
    "\n",
    "  for i in range(64773 - 12130):\n",
    "    X.append(X_[i])\n",
    "    y.append(0)\n",
    "  del X_[0:64773 - 12130]\n",
    "  for i in range(6108 - 1258):\n",
    "    val_X.append(X_[i])\n",
    "    val_y.append(0)\n",
    "\n",
    "  X, y = shuffle(X,y)\n",
    "  val_X, val_y = shuffle(val_X,val_y)\n",
    "\n",
    "  return X, val_X, y, val_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HmvRDCqmaa_i"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7KNA5r-7afVp"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, X, y, training=True, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        self.training = training\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img = self.X[idx]\n",
    "\n",
    "        if self.transform is not None:\n",
    "          res = self.transform(image=img)\n",
    "          img = res['image']\n",
    "        \n",
    "        img = np.rollaxis(img, 2, 0)\n",
    "        # img = np.array(img).astype(np.float32) / 255.\n",
    "\n",
    "        labels = self.y[idx]\n",
    "        labels = np.array(labels).astype(np.float32)\n",
    "        return [img, labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-xvk_DhD1iUn"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "dcIJUiPx1DgP",
    "outputId": "d8024ba7-ca65-4aed-c2c8-042a5274fdf4"
   },
   "outputs": [],
   "source": [
    "#Trying out different pre-trained models\n",
    "\n",
    "!pip install pytorchcv --quiet\n",
    "from pytorchcv.model_provider import get_model\n",
    "\n",
    "model = get_model(\"xception\", pretrained=True)\n",
    "#model = get_model(\"resnet18\", pretrained=True)\n",
    "#model = get_model(\"InceptionV4\", pretrained=True)\n",
    "\n",
    "\n",
    "model = nn.Sequential(*list(model.children())[:-1]) # Remove original output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGr9EuSX1ZYI"
   },
   "outputs": [],
   "source": [
    "model[0].final_block.pool = nn.Sequential(nn.AdaptiveAvgPool2d(1))\n",
    "#model[0].final_pool = nn.Sequential(nn.AdaptiveAvgPool2d(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEVBeVoW1cJX"
   },
   "outputs": [],
   "source": [
    "class Head(torch.nn.Module):\n",
    "  def __init__(self, in_f, out_f):\n",
    "    super(Head, self).__init__()\n",
    "    \n",
    "    self.f = nn.Flatten()\n",
    "    self.l = nn.Linear(in_f, 512)\n",
    "    self.d = nn.Dropout(0.50)\n",
    "    self.o = nn.Linear(512, out_f)\n",
    "    self.b1 = nn.BatchNorm1d(in_f)\n",
    "    self.b2 = nn.BatchNorm1d(512)\n",
    "    self.r = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.f(x)\n",
    "    x = self.b1(x)\n",
    "    x = self.d(x)\n",
    "\n",
    "    x = self.l(x)\n",
    "    x = self.r(x)\n",
    "    x = self.b2(x)\n",
    "    x = self.d(x)\n",
    "\n",
    "    out = self.o(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FRyOSBXy1wim"
   },
   "outputs": [],
   "source": [
    "class FCN(torch.nn.Module):\n",
    "  def __init__(self, base, in_f):\n",
    "    super(FCN, self).__init__()\n",
    "    self.base = base\n",
    "    self.h1 = Head(in_f, 1)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.base(x)\n",
    "    return self.h1(x)\n",
    "\n",
    "model = FCN(model, 2048)\n",
    "\n",
    "#model = FCN(model, 1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OPA6IyUJ1yxU"
   },
   "outputs": [],
   "source": [
    "# !pip install torchtoolbox --quiet\n",
    "# from torchtoolbox.tools import summary\n",
    "\n",
    "# model.cuda()\n",
    "# summary(model, torch.rand((1, 3, 150, 150)).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZv7D2KQ2YBk"
   },
   "source": [
    "# Train Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jc3QTjqj2XkJ"
   },
   "outputs": [],
   "source": [
    "def criterion1(pred1, targets):\n",
    "  l1 = F.binary_cross_entropy(F.sigmoid(pred1), targets)\n",
    "  return l1\n",
    "\n",
    "def train_model(epoch, optimizer, scheduler=None, history=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    t = tqdm(train_loader)\n",
    "    for i, (img_batch, y_batch) in enumerate(t):\n",
    "        img_batch = img_batch.cuda().float()\n",
    "        y_batch = y_batch.cuda().float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(img_batch)\n",
    "        loss = criterion1(out, y_batch)\n",
    "\n",
    "        total_loss += loss\n",
    "        t.set_description(f'Epoch {epoch+1}/{n_epochs}, LR: %6f, Loss: %.4f'%(optimizer.state_dict()['param_groups'][0]['lr'],total_loss/(i+1)))\n",
    "\n",
    "        if history is not None:\n",
    "          history.loc[epoch + i / len(X), 'train_loss'] = loss.data.cpu().numpy()\n",
    "          history.loc[epoch + i / len(X), 'lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "          scheduler.step()\n",
    "\n",
    "def evaluate_model(epoch, scheduler=None, history=None):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    pred = []\n",
    "    real = []\n",
    "    with torch.no_grad():\n",
    "        for img_batch, y_batch in val_loader:\n",
    "            img_batch = img_batch.cuda().float()\n",
    "            y_batch = y_batch.cuda().float()\n",
    "\n",
    "            o1 = model(img_batch)\n",
    "            l1 = criterion1(o1, y_batch)\n",
    "            loss += l1\n",
    "            \n",
    "            for j in o1:\n",
    "              pred.append(F.sigmoid(j))\n",
    "            for i in y_batch:\n",
    "              real.append(i.data.cpu())\n",
    "    \n",
    "    pred = [p.data.cpu().numpy() for p in pred]\n",
    "    pred2 = pred\n",
    "    pred = [np.round(p) for p in pred]\n",
    "    pred = np.array(pred)\n",
    "    acc = sklearn.metrics.recall_score(real, pred, average='macro')\n",
    "\n",
    "    real = [r.item() for r in real]\n",
    "    pred2 = np.array(pred2).clip(0.1, 0.9)\n",
    "    kaggle = sklearn.metrics.log_loss(real, pred2)\n",
    "\n",
    "    loss /= len(val_loader)\n",
    "    \n",
    "    if history is not None:\n",
    "        history.loc[epoch, 'dev_loss'] = loss.cpu().numpy()\n",
    "    \n",
    "    if scheduler is not None:\n",
    "      scheduler.step(loss)\n",
    "\n",
    "    print(f'Dev loss: %.4f, Acc: %.6f, Kaggle: %.6f'%(loss,acc,kaggle))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XAhEFXSVKsyr"
   },
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "n25nfarz8Gfi",
    "outputId": "9961d38f-8461-4535-ef15-2a3d06ae64cd"
   },
   "outputs": [],
   "source": [
    "X, val_X, y, val_y = get_random_sampling(paths, y, val_paths, val_y)\n",
    "\n",
    "print('There are '+str(y.count(1))+' fake train samples')\n",
    "print('There are '+str(y.count(0))+' real train samples')\n",
    "print('There are '+str(val_y.count(1))+' fake val samples')\n",
    "print('There are '+str(val_y.count(0))+' real val samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kfCLL0pt9Vh-"
   },
   "outputs": [],
   "source": [
    "import albumentations\n",
    "from albumentations.augmentations.transforms import ShiftScaleRotate, HorizontalFlip, Normalize, RandomBrightnessContrast, MotionBlur, Blur, GaussNoise, JpegCompression\n",
    "train_transform = albumentations.Compose([\n",
    "                                          ShiftScaleRotate(p=0.3, scale_limit=0.25, border_mode=1, rotate_limit=25),\n",
    "                                          HorizontalFlip(p=0.2),\n",
    "                                          RandomBrightnessContrast(p=0.3, brightness_limit=0.25, contrast_limit=0.5),\n",
    "                                          MotionBlur(p=.2),\n",
    "                                          GaussNoise(p=.2),\n",
    "                                          JpegCompression(p=.2, quality_lower=50),\n",
    "                                          Normalize()\n",
    "])\n",
    "val_transform = albumentations.Compose([\n",
    "                                          Normalize()\n",
    "])\n",
    "\n",
    "train_dataset = ImageDataset(X, y, transform=train_transform)\n",
    "val_dataset = ImageDataset(val_X, val_y, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "colab_type": "code",
    "id": "P0Z_BWFJ-E5A",
    "outputId": "db70092d-f2b0-4e17-fdfe-ffbb32bd9630"
   },
   "outputs": [],
   "source": [
    "nrow, ncol = 5, 6\n",
    "fig, axes = plt.subplots(nrow, ncol, figsize=(20, 8))\n",
    "axes = axes.flatten()\n",
    "for i, ax in enumerate(axes):\n",
    "    image, label = train_dataset[i]\n",
    "    image = np.rollaxis(image, 0, 3)\n",
    "    image = image*std + mean\n",
    "    image = np.clip(image, 0., 1.)\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(f'label: {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "colab_type": "code",
    "id": "RJmdT2spBEU1",
    "outputId": "bd51ed41-f0b2-49ec-8fa1-7c890243b78d"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "history = pd.DataFrame()\n",
    "history2 = pd.DataFrame()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "best = 1e10\n",
    "n_epochs = 60\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.005)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, mode='min', factor=0.7, verbose=True, min_lr=1e-5)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    train_model(epoch, optimizer, scheduler=None, history=history)\n",
    "    \n",
    "    loss = evaluate_model(epoch, scheduler=scheduler, history=history2)\n",
    "    \n",
    "    if loss < best:\n",
    "      best = loss\n",
    "      print(f'Saving best model...')\n",
    "      torch.save(model.state_dict(), f'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zbaUUqLIKwst"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtSjo9DYtoEL"
   },
   "outputs": [],
   "source": [
    "history.plot()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "AaU3SeKMz_qm",
    "XsefoEdR1gHt"
   ],
   "machine_shape": "hm",
   "name": "Deepfake_Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
